Step	Training Loss	Validation Loss	
100	0.966100	0.893694	100
200	0.755200	0.658171	200
300	0.427500	0.456447	300
400	0.260500	0.288264	400
500	0.172500	0.180974	500
600	0.081600	0.112066	600
700	0.064200	0.091227	700
800	0.059900	0.069850	800
Step: 20 | {'loss': 1.2417, 'grad_norm': 0.3937358558177948, 'learning_rate': 0.00014615384615384615, 'epoch': 0.07191011235955057}
Step: 40 | {'loss': 1.1122, 'grad_norm': 0.33855462074279785, 'learning_rate': 0.0001967940813810111, 'epoch': 0.14382022471910114}
Step: 60 | {'loss': 1.0496, 'grad_norm': 0.48817193508148193, 'learning_rate': 0.00019186189889025895, 'epoch': 0.2157303370786517}
Step: 80 | {'loss': 0.9435, 'grad_norm': 0.48183050751686096, 'learning_rate': 0.0001869297163995068, 'epoch': 0.2876404494382023}
Step: 100 | {'loss': 0.9661, 'grad_norm': 0.6421177983283997, 'learning_rate': 0.00018199753390875462, 'epoch': 0.3595505617977528}
Step: 100 | {'eval_loss': 0.8936936259269714, 'eval_runtime': 12.0701, 'eval_samples_per_second': 4.142, 'eval_steps_per_second': 4.142, 'epoch': 0.3595505617977528}
Step: 120 | {'loss': 0.8608, 'grad_norm': 0.389823853969574, 'learning_rate': 0.00017706535141800246, 'epoch': 0.4314606741573034}
Step: 140 | {'loss': 0.8933, 'grad_norm': 0.4837062358856201, 'learning_rate': 0.00017213316892725032, 'epoch': 0.503370786516854}
Step: 160 | {'loss': 0.8708, 'grad_norm': 0.552372932434082, 'learning_rate': 0.00016720098643649816, 'epoch': 0.5752808988764045}
Step: 180 | {'loss': 0.762, 'grad_norm': 0.5400437116622925, 'learning_rate': 0.000162268803945746, 'epoch': 0.647191011235955}
Step: 200 | {'loss': 0.7552, 'grad_norm': 0.6263315677642822, 'learning_rate': 0.00015733662145499383, 'epoch': 0.7191011235955056}
Step: 200 | {'eval_loss': 0.6581707000732422, 'eval_runtime': 12.1733, 'eval_samples_per_second': 4.107, 'eval_steps_per_second': 4.107, 'epoch': 0.7191011235955056}
Step: 220 | {'loss': 0.6924, 'grad_norm': 0.6552025675773621, 'learning_rate': 0.0001524044389642417, 'epoch': 0.7910112359550562}
Step: 240 | {'loss': 0.682, 'grad_norm': 0.7458840012550354, 'learning_rate': 0.00014747225647348953, 'epoch': 0.8629213483146068}
Step: 260 | {'loss': 0.6248, 'grad_norm': 0.7553634643554688, 'learning_rate': 0.00014254007398273736, 'epoch': 0.9348314606741573}
Step: 280 | {'loss': 0.5664, 'grad_norm': 0.8144695162773132, 'learning_rate': 0.0001376078914919852, 'epoch': 1.0035955056179775}
Step: 300 | {'loss': 0.4275, 'grad_norm': 1.0283000469207764, 'learning_rate': 0.00013267570900123306, 'epoch': 1.075505617977528}
Step: 300 | {'eval_loss': 0.4564467966556549, 'eval_runtime': 12.1656, 'eval_samples_per_second': 4.11, 'eval_steps_per_second': 4.11, 'epoch': 1.075505617977528}
Step: 320 | {'loss': 0.384, 'grad_norm': 0.8322269320487976, 'learning_rate': 0.0001277435265104809, 'epoch': 1.1474157303370787}
Step: 340 | {'loss': 0.3793, 'grad_norm': 0.7983018159866333, 'learning_rate': 0.00012281134401972873, 'epoch': 1.2193258426966291}
Step: 360 | {'loss': 0.3552, 'grad_norm': 0.9646588563919067, 'learning_rate': 0.00011787916152897658, 'epoch': 1.2912359550561798}
Step: 380 | {'loss': 0.2926, 'grad_norm': 0.91010582447052, 'learning_rate': 0.00011294697903822442, 'epoch': 1.3631460674157303}
Step: 400 | {'loss': 0.2605, 'grad_norm': 0.9633097052574158, 'learning_rate': 0.00010801479654747227, 'epoch': 1.4350561797752808}
Step: 400 | {'eval_loss': 0.2882644832134247, 'eval_runtime': 12.2032, 'eval_samples_per_second': 4.097, 'eval_steps_per_second': 4.097, 'epoch': 1.4350561797752808}
Step: 420 | {'loss': 0.233, 'grad_norm': 0.7532303929328918, 'learning_rate': 0.0001030826140567201, 'epoch': 1.5069662921348315}
Step: 440 | {'loss': 0.2374, 'grad_norm': 1.070370078086853, 'learning_rate': 9.815043156596795e-05, 'epoch': 1.5788764044943822}
Step: 460 | {'loss': 0.2172, 'grad_norm': 0.7735735774040222, 'learning_rate': 9.321824907521579e-05, 'epoch': 1.6507865168539326}
Step: 480 | {'loss': 0.1802, 'grad_norm': 0.7044265866279602, 'learning_rate': 8.828606658446364e-05, 'epoch': 1.722696629213483}
Step: 500 | {'loss': 0.1725, 'grad_norm': 0.8757086396217346, 'learning_rate': 8.335388409371147e-05, 'epoch': 1.7946067415730336}
Step: 500 | {'eval_loss': 0.18097393214702606, 'eval_runtime': 12.0874, 'eval_samples_per_second': 4.137, 'eval_steps_per_second': 4.137, 'epoch': 1.7946067415730336}
Step: 520 | {'loss': 0.1429, 'grad_norm': 0.6680859923362732, 'learning_rate': 7.842170160295932e-05, 'epoch': 1.8665168539325843}
Step: 540 | {'loss': 0.1505, 'grad_norm': 0.6231076121330261, 'learning_rate': 7.348951911220715e-05, 'epoch': 1.938426966292135}
Step: 560 | {'loss': 0.1203, 'grad_norm': 0.5871575474739075, 'learning_rate': 6.8557336621455e-05, 'epoch': 2.007191011235955}
Step: 580 | {'loss': 0.079, 'grad_norm': 0.6220036149024963, 'learning_rate': 6.362515413070283e-05, 'epoch': 2.0791011235955055}
Step: 600 | {'loss': 0.0816, 'grad_norm': 0.6264476180076599, 'learning_rate': 5.869297163995068e-05, 'epoch': 2.151011235955056}
Step: 600 | {'eval_loss': 0.112065888941288, 'eval_runtime': 12.1798, 'eval_samples_per_second': 4.105, 'eval_steps_per_second': 4.105, 'epoch': 2.151011235955056}
Step: 620 | {'loss': 0.0735, 'grad_norm': 0.45889711380004883, 'learning_rate': 5.376078914919852e-05, 'epoch': 2.222921348314607}
Step: 640 | {'loss': 0.0755, 'grad_norm': 0.4937054514884949, 'learning_rate': 4.8828606658446366e-05, 'epoch': 2.2948314606741573}
Step: 660 | {'loss': 0.073, 'grad_norm': 0.6464962959289551, 'learning_rate': 4.389642416769421e-05, 'epoch': 2.366741573033708}
Step: 680 | {'loss': 0.0615, 'grad_norm': 0.455638587474823, 'learning_rate': 3.896424167694205e-05, 'epoch': 2.4386516853932583}
Step: 700 | {'loss': 0.0642, 'grad_norm': 0.5445465445518494, 'learning_rate': 3.4032059186189894e-05, 'epoch': 2.5105617977528087}
Step: 700 | {'eval_loss': 0.09122664481401443, 'eval_runtime': 12.2496, 'eval_samples_per_second': 4.082, 'eval_steps_per_second': 4.082, 'epoch': 2.5105617977528087}
Step: 720 | {'loss': 0.066, 'grad_norm': 0.515597403049469, 'learning_rate': 2.9099876695437733e-05, 'epoch': 2.5824719101123597}
Step: 740 | {'loss': 0.0666, 'grad_norm': 0.5648301243782043, 'learning_rate': 2.4167694204685575e-05, 'epoch': 2.65438202247191}
Step: 760 | {'loss': 0.0634, 'grad_norm': 0.5228062272071838, 'learning_rate': 1.9235511713933415e-05, 'epoch': 2.7262921348314606}
Step: 780 | {'loss': 0.0595, 'grad_norm': 0.42037153244018555, 'learning_rate': 1.4303329223181259e-05, 'epoch': 2.798202247191011}
Step: 800 | {'loss': 0.0599, 'grad_norm': 0.38608846068382263, 'learning_rate': 9.371146732429101e-06, 'epoch': 2.8701123595505615}
Step: 800 | {'eval_loss': 0.06984993070363998, 'eval_runtime': 12.147, 'eval_samples_per_second': 4.116, 'eval_steps_per_second': 4.116, 'epoch': 2.8701123595505615}
Step: 820 | {'loss': 0.0533, 'grad_norm': 0.32325583696365356, 'learning_rate': 4.438964241676942e-06, 'epoch': 2.9420224719101125}
Step: 837 | {'train_runtime': 5605.1051, 'train_samples_per_second': 2.382, 'train_steps_per_second': 0.149, 'total_flos': 5.076452467073434e+16, 'train_loss': 0.3941896228807374, 'epoch': 3.0}
TrainOutput(global_step=837, training_loss=0.3941896228807374, metrics={'train_runtime': 5605.1051, 'train_samples_per_second': 2.382, 'train_steps_per_second': 0.149, 'total_flos': 5.076452467073434e+16, 'train_loss': 0.3941896228807374, 'epoch': 3.0, 'step': 837})