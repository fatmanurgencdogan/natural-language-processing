Step	Training Loss	Validation Loss	
100	1.040200	1.091966	100
200	1.081700	1.073217	200
300	0.945300	1.068312	300
400	0.973700	1.067644	400
500	0.941900	1.059660	500
600	0.821200	1.087890	600
700	0.827800	1.084162	700
Step: 20 | {'loss': 1.2487, 'grad_norm': 0.42755886912345886, 'learning_rate': 0.00014615384615384615, 'epoch': 0.07191011235955057}
Step: 40 | {'loss': 1.0905, 'grad_norm': 0.35111063718795776, 'learning_rate': 0.0001967940813810111, 'epoch': 0.14382022471910114}
Step: 60 | {'loss': 1.0575, 'grad_norm': 0.5026016235351562, 'learning_rate': 0.00019186189889025895, 'epoch': 0.2157303370786517}
Step: 80 | {'loss': 1.0741, 'grad_norm': 0.4146289527416229, 'learning_rate': 0.0001869297163995068, 'epoch': 0.2876404494382023}
Step: 100 | {'loss': 1.0402, 'grad_norm': 0.42648476362228394, 'learning_rate': 0.00018199753390875462, 'epoch': 0.3595505617977528}
Step: 100 | {'eval_loss': 1.091965913772583, 'eval_runtime': 12.5551, 'eval_samples_per_second': 3.982, 'eval_steps_per_second': 3.982, 'epoch': 0.3595505617977528}
Step: 120 | {'loss': 1.1051, 'grad_norm': 0.34107887744903564, 'learning_rate': 0.00017706535141800246, 'epoch': 0.4314606741573034}
Step: 140 | {'loss': 1.0742, 'grad_norm': 0.3379110097885132, 'learning_rate': 0.00017213316892725032, 'epoch': 0.503370786516854}
Step: 160 | {'loss': 1.0611, 'grad_norm': 0.3129919469356537, 'learning_rate': 0.00016720098643649816, 'epoch': 0.5752808988764045}
Step: 180 | {'loss': 1.0704, 'grad_norm': 0.4237152636051178, 'learning_rate': 0.000162268803945746, 'epoch': 0.647191011235955}
Step: 200 | {'loss': 1.0817, 'grad_norm': 0.5296521782875061, 'learning_rate': 0.00015733662145499383, 'epoch': 0.7191011235955056}
Step: 200 | {'eval_loss': 1.0732172727584839, 'eval_runtime': 12.5746, 'eval_samples_per_second': 3.976, 'eval_steps_per_second': 3.976, 'epoch': 0.7191011235955056}
Step: 220 | {'loss': 1.0295, 'grad_norm': 0.31632199883461, 'learning_rate': 0.0001524044389642417, 'epoch': 0.7910112359550562}
Step: 240 | {'loss': 1.0859, 'grad_norm': 0.3708372414112091, 'learning_rate': 0.00014747225647348953, 'epoch': 0.8629213483146068}
Step: 260 | {'loss': 1.0126, 'grad_norm': 0.44618701934814453, 'learning_rate': 0.00014254007398273736, 'epoch': 0.9348314606741573}
Step: 280 | {'loss': 1.0836, 'grad_norm': 0.30411210656166077, 'learning_rate': 0.0001376078914919852, 'epoch': 1.0035955056179775}
Step: 300 | {'loss': 0.9453, 'grad_norm': 0.3321811258792877, 'learning_rate': 0.00013267570900123306, 'epoch': 1.075505617977528}
Step: 300 | {'eval_loss': 1.068312406539917, 'eval_runtime': 12.523, 'eval_samples_per_second': 3.993, 'eval_steps_per_second': 3.993, 'epoch': 1.075505617977528}
Step: 320 | {'loss': 0.948, 'grad_norm': 0.3892005383968353, 'learning_rate': 0.0001277435265104809, 'epoch': 1.1474157303370787}
Step: 340 | {'loss': 0.9231, 'grad_norm': 0.46387824416160583, 'learning_rate': 0.00012281134401972873, 'epoch': 1.2193258426966291}
Step: 360 | {'loss': 0.9564, 'grad_norm': 0.33995795249938965, 'learning_rate': 0.00011787916152897658, 'epoch': 1.2912359550561798}
Step: 380 | {'loss': 0.9796, 'grad_norm': 0.4036220908164978, 'learning_rate': 0.00011294697903822442, 'epoch': 1.3631460674157303}
Step: 400 | {'loss': 0.9737, 'grad_norm': 0.380504846572876, 'learning_rate': 0.00010801479654747227, 'epoch': 1.4350561797752808}
Step: 400 | {'eval_loss': 1.0676437616348267, 'eval_runtime': 12.583, 'eval_samples_per_second': 3.974, 'eval_steps_per_second': 3.974, 'epoch': 1.4350561797752808}
Step: 420 | {'loss': 0.9698, 'grad_norm': 0.3419731855392456, 'learning_rate': 0.0001030826140567201, 'epoch': 1.5069662921348315}
Step: 440 | {'loss': 0.9282, 'grad_norm': 0.3698734641075134, 'learning_rate': 9.815043156596795e-05, 'epoch': 1.5788764044943822}
Step: 460 | {'loss': 0.9328, 'grad_norm': 0.39656463265419006, 'learning_rate': 9.321824907521579e-05, 'epoch': 1.6507865168539326}
Step: 480 | {'loss': 0.8881, 'grad_norm': 0.4078434109687805, 'learning_rate': 8.828606658446364e-05, 'epoch': 1.722696629213483}
Step: 500 | {'loss': 0.9419, 'grad_norm': 0.41997620463371277, 'learning_rate': 8.335388409371147e-05, 'epoch': 1.7946067415730336}
Step: 500 | {'eval_loss': 1.0596600770950317, 'eval_runtime': 12.6485, 'eval_samples_per_second': 3.953, 'eval_steps_per_second': 3.953, 'epoch': 1.7946067415730336}
Step: 520 | {'loss': 0.9437, 'grad_norm': 0.3844109773635864, 'learning_rate': 7.842170160295932e-05, 'epoch': 1.8665168539325843}
Step: 540 | {'loss': 0.9652, 'grad_norm': 0.39798855781555176, 'learning_rate': 7.348951911220715e-05, 'epoch': 1.938426966292135}
Step: 560 | {'loss': 0.9323, 'grad_norm': 0.3582994043827057, 'learning_rate': 6.8557336621455e-05, 'epoch': 2.007191011235955}
Step: 580 | {'loss': 0.8935, 'grad_norm': 0.4335671663284302, 'learning_rate': 6.362515413070283e-05, 'epoch': 2.0791011235955055}
Step: 600 | {'loss': 0.8212, 'grad_norm': 0.5451453924179077, 'learning_rate': 5.869297163995068e-05, 'epoch': 2.151011235955056}
Step: 600 | {'eval_loss': 1.0878901481628418, 'eval_runtime': 12.5408, 'eval_samples_per_second': 3.987, 'eval_steps_per_second': 3.987, 'epoch': 2.151011235955056}
Step: 620 | {'loss': 0.8301, 'grad_norm': 0.4210798442363739, 'learning_rate': 5.376078914919852e-05, 'epoch': 2.222921348314607}
Step: 640 | {'loss': 0.8442, 'grad_norm': 0.4442959725856781, 'learning_rate': 4.8828606658446366e-05, 'epoch': 2.2948314606741573}
Step: 660 | {'loss': 0.8372, 'grad_norm': 0.450735479593277, 'learning_rate': 4.389642416769421e-05, 'epoch': 2.366741573033708}
Step: 680 | {'loss': 0.8531, 'grad_norm': 0.499648779630661, 'learning_rate': 3.896424167694205e-05, 'epoch': 2.4386516853932583}
Step: 700 | {'loss': 0.8278, 'grad_norm': 0.4727049171924591, 'learning_rate': 3.4032059186189894e-05, 'epoch': 2.5105617977528087}
Step: 700 | {'eval_loss': 1.0841618776321411, 'eval_runtime': 12.6474, 'eval_samples_per_second': 3.953, 'eval_steps_per_second': 3.953, 'epoch': 2.5105617977528087}
Step: 700 | {'train_runtime': 4980.7122, 'train_samples_per_second': 2.68, 'train_steps_per_second': 0.168, 'total_flos': 4.279430892383539e+16, 'train_loss': 0.9785841560363769, 'epoch': 2.5105617977528087}
TrainOutput(global_step=700, training_loss=0.9785841560363769, metrics={'train_runtime': 4980.7122, 'train_samples_per_second': 2.68, 'train_steps_per_second': 0.168, 'total_flos': 4.279430892383539e+16, 'train_loss': 0.9785841560363769, 'epoch': 2.5105617977528087, 'step': 700})